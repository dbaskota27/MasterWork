{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "\n",
    "environment = 'Test'\n",
    "\n",
    "if (path.exists(\"../Library/cus_databases.ipynb\")):\n",
    "    environment = 'Test'\n",
    "    Date_Override = 'Y'\n",
    "else:\n",
    "    environment = 'Prod'\n",
    "    Date_Override = 'N'\n",
    "\n",
    "print('environment is set to: ',environment)\n",
    "\n",
    "clientCode = 'ALL'\n",
    "TrainingTypeID = 1\n",
    "Ranking_ID = 1\n",
    "\n",
    "def splitter(td):\n",
    "    td = str(td).split(' ')[-1:][0]\n",
    "\n",
    "    return td\n",
    "\n",
    "Max_Round_Robins = 3\n",
    "print('Round Robin is set to: ',str(Max_Round_Robins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import xlsxwriter\n",
    "import os\n",
    "import pyodbc \n",
    "import numpy as np\n",
    "from datetime import date, timedelta, datetime\n",
    "import math\n",
    "\n",
    "import jinja2\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "import urllib.parse\n",
    "from pandas import Series, DataFrame\n",
    "import gc\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "import json\n",
    "import urllib\n",
    "import boto3\n",
    "from boto.s3.key import Key\n",
    "import base64\n",
    "\n",
    "%run ../Library/cus_databases.ipynb\n",
    "%run ../Library/datetime_utils.ipynb\n",
    "\n",
    "focus_db = get_db_SS_focus()\n",
    "focus_dev = get_db_SS_focus_dev()\n",
    "report_RO_DB = Reporting_Read_Only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Front End Controller\n",
    "\n",
    "%run ../Library/Environment_Controller.ipynb\n",
    "\n",
    "time_format = '%Y-%m-%d' \n",
    "\n",
    "run_date = datetime.now()\n",
    "#Date Override\n",
    "if(Date_Override == 'Y'):\n",
    "    print('Date Override is On')\n",
    "    start_date = (run_date.date() - timedelta(days=(run_date).weekday()))+ timedelta(7)\n",
    "\n",
    "else:\n",
    "    start_date = (run_date.date() - timedelta(days=(run_date).weekday()))\n",
    "    Ranking_ID, clientCode, TrainingTypeID, start_date_alt = Environment_control_Scheduling_DateRange(environment,clientCode,TrainingTypeID,Ranking_ID)\n",
    "    \n",
    "    if(start_date_alt == 'Next_Week'):\n",
    "        print('Date is nil, Setting to next Monday from now')\n",
    "        start_date = start_date + timedelta(7)\n",
    "        \n",
    "    elif(start_date_alt == 'Next_2_Week'):\n",
    "        print('Date is 2 Weeks out, Setting to 2 Monday from now')\n",
    "        start_date = start_date + timedelta(14)    \n",
    "        \n",
    "    elif(start_date_alt == 'Next_3_Week'):\n",
    "        print('Date is 3 Weeks out, Setting to 3 Monday from now')\n",
    "        start_date = start_date + timedelta(21)    \n",
    "        \n",
    "    elif(start_date_alt == 'Next_4_Week'):\n",
    "        print('Date is 4 Weeks out, Setting to 4 Monday from now')\n",
    "        start_date = start_date + timedelta(28)         \n",
    "\n",
    "    elif(start_date_alt == 'Current_Week'):\n",
    "        print('Date is 0 Week out, Setting to this week')\n",
    "        start_date = start_date + timedelta(0)  \n",
    "        \n",
    "    elif(start_date_alt == '1_WeekAgo'):\n",
    "        print('Date is 1 Week out, Setting to 1 week ago')\n",
    "        start_date = start_date - timedelta(7)  \n",
    "    \n",
    "    elif(start_date_alt == '2_WeekAgo'):\n",
    "        print('Date is 2 Weeks out, Setting to 2 week ago')\n",
    "        start_date = start_date - timedelta(14)      \n",
    "        \n",
    "    elif(start_date_alt == '3_WeekAgo'):\n",
    "        print('Date is 3 Weeks out, Setting to 3 week ago')\n",
    "        start_date = start_date - timedelta(21)    \n",
    "    \n",
    "    else:\n",
    "        print('Date is Current Week')\n",
    "\n",
    "\n",
    "end_date = start_date + timedelta(7)\n",
    "    \n",
    "    \n",
    "base = start_date\n",
    "date_list = [base + timedelta(days=x) for x in range(7)]          \n",
    "print (\"Week start: %s   Week end: %s\" % (start_date, end_date))\n",
    "\n",
    "if(clientCode == 'ALL'):\n",
    "    print(\"Running for All clients\")\n",
    "else:\n",
    "    print(\"Running for client: \", clientCode)\n",
    "    \n",
    "print('-----------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_db = get_db_SS_focus()\n",
    "report_RO_DB = Reporting_Read_Only()\n",
    "\n",
    "if(clientCode == 'ALL'):\n",
    "    sql=\"\"\"get your data\"\"\"\n",
    "    sql_pd1 = pd.read_sql(sql, focus_db)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    sql=\"\"\"get your data\n",
    "        \"\"\"   \n",
    "    sql_pd1 = pd.read_sql(sql, focus_db)\n",
    "\n",
    "    sql_pd4 = \"\"\"  \n",
    "   get your data\n",
    "    \"\"\"\n",
    "    sql_pd4 = pd.read_sql(sql_pd4, report_RO_DB)\n",
    "    sql_pd1 = pd.merge(sql_pd1,sql_pd4,how='left',left_on='Department',right_on='Department')\n",
    "\n",
    "    sql_pd1 = sql_pd1[sql_pd1['Client'] == clientCode].reset_index(drop=True)\n",
    "    sql_pd1 = sql_pd1[['MemberID', 'Name', 'Department', 'Schedule']]\n",
    "    sql_pd1 = sql_pd1[sql_pd1['Schedule'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_df = sql_pd1\n",
    "# output looks like this\n",
    "# MemberID Name Department Schedule\n",
    "# 1 a x {\"Monday\":[[\"08:00\",\"17:00\"]],\"Tuesday\":[[\"08:00\",\"17:00\"]],\"Wednesday\":[[\"08:00\",\"17:00\"]],\"Thursday\":[[\"08:00\",\"17:00\"]],\"Friday\":[[\"08:00\",\"17:00\"]]}\n",
    "# 2 b y {\"Monday\":[[\"07:00\",\"15:30\"]],\"Tuesday\":[[\"07:00\",\"15:30\"]],\"Wednesday\":[[\"07:00\",\"15:30\"]],\"Thursday\":[[\"07:00\",\"15:30\"]],\"Friday\":[[\"07:00\",\"15:30\"]]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_to_datetime(date_str, time_str):\n",
    "    # Handle '24:00' by converting it to '00:00' of the next day\n",
    "    if time_str == '24:00':\n",
    "        time_str = '00:00'\n",
    "        date_str = (datetime.strptime(date_str, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    try:\n",
    "        return datetime.strptime(f\"{date_str} {time_str}\", \"%Y-%m-%d %H:%M\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting time: {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_shift_metrics(member_id,Name,Department, start_date, day_name, shift):\n",
    "    start_time, end_time = shift\n",
    "    start_datetime = convert_time_to_datetime(start_date, start_time)\n",
    "    end_datetime = convert_time_to_datetime(start_date, end_time)\n",
    "    \n",
    "    scheduled_datetime = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    \n",
    "    start_seconds = (start_datetime - scheduled_datetime).total_seconds()\n",
    "    end_seconds = (end_datetime - scheduled_datetime).total_seconds()\n",
    "    \n",
    "    if start_datetime is None or end_datetime is None:\n",
    "        return None\n",
    "\n",
    "    if end_datetime < start_datetime:\n",
    "        # Handle overnight shift\n",
    "        end_datetime += timedelta(days=1)\n",
    "    \n",
    "    shift_length = (end_datetime - start_datetime).total_seconds()\n",
    "    shift_minutes = shift_length / 60\n",
    "    \n",
    "    return {\n",
    "        'MemberID': member_id,\n",
    "        'Name': Name,  \n",
    "        'Department': Department, \n",
    "        'Scheduled_Date': start_date,\n",
    "        'Scheduled_Day': day_name,\n",
    "        'Start_Time': start_time,\n",
    "        'End_Time': end_time,\n",
    "        'Start_DateTime': start_datetime,\n",
    "        'End_DateTime': end_datetime,\n",
    "        'Shift_Length': shift_length,\n",
    "        'Start': start_seconds,\n",
    "        'End': end_seconds,\n",
    "        'ShiftMinutes': shift_minutes\n",
    "    }\n",
    "\n",
    "def find_monday(date):\n",
    "    \"\"\"Find the Monday of the week for a given date\"\"\"\n",
    "    return date - timedelta(days=date.weekday())\n",
    "\n",
    "def generate_metrics(schedule_df, reference_date):\n",
    "    all_metrics = []\n",
    "    days_of_week = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\",\"Saturday\",\"Sunday\"]\n",
    "    \n",
    "    # Find Monday of the week for the given reference date\n",
    "    start_of_week = find_monday(reference_date)\n",
    "    \n",
    "    # Ensure Schedule column is in dictionary format (if it's already a dictionary, no need to convert)\n",
    "    def ensure_dict(schedule):\n",
    "        if isinstance(schedule, str):\n",
    "            try:\n",
    "                return json.loads(schedule)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON string: {schedule}. Exception: {e}\")\n",
    "                return {}\n",
    "        elif isinstance(schedule, dict):\n",
    "            return schedule\n",
    "        else:\n",
    "            print(f\"Unexpected format for schedule: {schedule}\")\n",
    "            return {}\n",
    "    \n",
    "    schedule_df['Schedule'] = schedule_df['Schedule'].apply(ensure_dict)\n",
    "    \n",
    "    for _, row in schedule_df.iterrows():\n",
    "        member_id = row['MemberID']\n",
    "        Name = row['Name']\n",
    "        Department = row['Department']\n",
    "\n",
    "        weekly_schedule = row['Schedule']\n",
    "        \n",
    "        # Debug: Check the type of weekly_schedule\n",
    "        if not isinstance(weekly_schedule, dict):\n",
    "            print(f\"Error: weekly_schedule is not a dictionary. It is: {type(weekly_schedule)}\")\n",
    "            continue\n",
    "        \n",
    "        for day_index, day_name in enumerate(days_of_week):\n",
    "            if day_name in weekly_schedule:\n",
    "                shifts = weekly_schedule[day_name]\n",
    "                \n",
    "                # Debug: Check the type of shifts\n",
    "                if not isinstance(shifts, list):\n",
    "                    print(f\"Error: Shifts for {day_name} are not a list. They are: {type(shifts)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Calculate the date for this day\n",
    "                date_str = (start_of_week + timedelta(days=day_index)).strftime(\"%Y-%m-%d\")\n",
    "                for shift in shifts:\n",
    "                    if not isinstance(shift, list) or len(shift) != 2:\n",
    "                        print(f\"Error: Invalid shift format for {day_name}. Shift: {shift}\")\n",
    "                        continue\n",
    "                        \n",
    "                    metrics = calculate_shift_metrics(member_id,Name,Department, date_str, day_name, shift)\n",
    "                    if metrics:  # Ensure metrics are not None\n",
    "                        all_metrics.append(metrics)\n",
    "    \n",
    "    return pd.DataFrame(all_metrics)\n",
    "\n",
    "reference_date = start_date \n",
    "\n",
    "# Generate metrics\n",
    "metrics_df = generate_metrics(schedule_df, reference_date)\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MemberID\tName\tDepartment\tScheduled_Date\tScheduled_Day\tStart_Time\tEnd_Time\tStart_DateTime\tEnd_DateTime\tShift_Length\tStart\tEnd\tShiftMinutes\n",
    "1\ta x\t\t2025-04-21\tMonday\t08:00\t17:00\t2025-04-21 08:00:00\t2025-04-21 17:00:00\t32400.0\t28800.0\t61200.0\t540.0\n",
    "1\ta y\t\t2025-04-22\tTuesday\t08:00\t17:00\t2025-04-22 08:00:00\t2025-04-22 17:00:00\t32400.0\t28800.0\t61200.0\t540.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = metrics_df\n",
    "\n",
    "# Convert to datetime\n",
    "df['Start_DateTime'] = pd.to_datetime(df['Start_DateTime'])\n",
    "df['End_DateTime'] = pd.to_datetime(df['End_DateTime'])\n",
    "df['Scheduled_DateTime'] = pd.to_datetime(df['Scheduled_Date'])\n",
    "\n",
    "# Sort by MemberID and Start_DateTime\n",
    "df.sort_values(by=['MemberID', 'Start_DateTime'], inplace=True)\n",
    "\n",
    "# Initialize lists to store results\n",
    "consolidated_shifts = []\n",
    "\n",
    "# Process each group of MemberID\n",
    "for member_id, group in df.groupby('MemberID'):\n",
    "    # Variables to store previous row information\n",
    "    prev_row = None\n",
    "\n",
    "    for idx, row in group.iterrows():\n",
    "        if prev_row is not None:\n",
    "            # If previous shift ends at 24:00 and current shift starts at 00:00, combine them\n",
    "            if prev_row['End_Time'] == '24:00' and row['Start_Time'] == '00:00':\n",
    "                consolidated_shifts.append({\n",
    "                    'MemberID': member_id,\n",
    "                    'Name': prev_row['Name'],\n",
    "                    'Department': prev_row['Department'],\n",
    "                    'Scheduled_Date': prev_row['Scheduled_Date'],\n",
    "                    'Scheduled_Day': prev_row['Scheduled_Day'],\n",
    "                    'Start_DateTime': prev_row['Start_DateTime'],\n",
    "                    'End_DateTime': row['End_DateTime'],\n",
    "                    'Shift_Length': (row['End_DateTime'] - prev_row['Start_DateTime']).total_seconds(),\n",
    "                    'ShiftMinutes': (row['End_DateTime'] - prev_row['Start_DateTime']).total_seconds() / 60,\n",
    "                    'Start': (prev_row['Start_DateTime'] - prev_row['Scheduled_DateTime']).total_seconds(),\n",
    "                    'End': (row['End_DateTime'] - prev_row['Scheduled_DateTime']).total_seconds(),\n",
    "                    'Overnight': \"Y\"\n",
    "                })\n",
    "                # Skip the current row as it's merged\n",
    "                prev_row = None\n",
    "            else:\n",
    "                # Check if the shift is overnight\n",
    "                overnight = \"Y\" if prev_row['Start_DateTime'].date() != prev_row['End_DateTime'].date() else \"N\"\n",
    "                \n",
    "                consolidated_shifts.append({\n",
    "                    'MemberID': member_id,\n",
    "                    'Name': prev_row['Name'],\n",
    "                    'Department': prev_row['Department'],\n",
    "                    'Scheduled_Date': prev_row['Scheduled_Date'],\n",
    "                    'Scheduled_Day': prev_row['Scheduled_Day'],\n",
    "                    'Start_DateTime': prev_row['Start_DateTime'],\n",
    "                    'End_DateTime': prev_row['End_DateTime'],\n",
    "                    'Shift_Length': (prev_row['End_DateTime'] - prev_row['Start_DateTime']).total_seconds(),\n",
    "                    'ShiftMinutes': (prev_row['End_DateTime'] - prev_row['Start_DateTime']).total_seconds() / 60,\n",
    "                    'Start': (prev_row['Start_DateTime'] - prev_row['Scheduled_DateTime']).total_seconds(),\n",
    "                    'End': (prev_row['End_DateTime'] - prev_row['Scheduled_DateTime']).total_seconds(),\n",
    "                    'Overnight': overnight\n",
    "                })\n",
    "                prev_row = row\n",
    "        else:\n",
    "            prev_row = row\n",
    "\n",
    "    # Add the last row if it wasn't merged\n",
    "    if prev_row is not None:\n",
    "        # Check if the shift is overnight\n",
    "        overnight = \"Y\" if prev_row['Start_DateTime'].date() != prev_row['End_DateTime'].date() else \"N\"\n",
    "\n",
    "        consolidated_shifts.append({\n",
    "            'MemberID': member_id,\n",
    "            'Name': prev_row['Name'],\n",
    "            'Department': prev_row['Department'],\n",
    "            'Scheduled_Date': prev_row['Scheduled_Date'],\n",
    "            'Scheduled_Day': prev_row['Scheduled_Day'],\n",
    "            'Start_DateTime': prev_row['Start_DateTime'],\n",
    "            'End_DateTime': prev_row['End_DateTime'],\n",
    "            'Shift_Length': (prev_row['End_DateTime'] - prev_row['Start_DateTime']).total_seconds(),\n",
    "            'ShiftMinutes': (prev_row['End_DateTime'] - prev_row['Start_DateTime']).total_seconds() / 60,\n",
    "            'Start': (prev_row['Start_DateTime'] - prev_row['Scheduled_DateTime']).total_seconds(),\n",
    "            'End': (prev_row['End_DateTime'] - prev_row['Scheduled_DateTime']).total_seconds(),\n",
    "            'Overnight': overnight\n",
    "        })\n",
    "\n",
    "consolidated_df = pd.DataFrame(consolidated_shifts)\n",
    "consolidated_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjustment for following week schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = consolidated_df\n",
    "# Convert Start_DateTime and End_DateTime to datetime format\n",
    "df['Start_DateTime'] = pd.to_datetime(df['Start_DateTime'])\n",
    "df['End_DateTime'] = pd.to_datetime(df['End_DateTime'])\n",
    "\n",
    "# Function to adjust the Sunday shift ending on Monday\n",
    "def adjust_sunday_shift(df):\n",
    "    # Identify the Sunday shift that continues into Monday\n",
    "    sunday_shift = df[(df['Scheduled_Day'] == 'Sunday') & (df['End_DateTime'].dt.weekday == 0)]\n",
    "    \n",
    "    # Loop through each Sunday shift\n",
    "    for idx, shift in sunday_shift.iterrows():\n",
    "        member_id = shift['MemberID']\n",
    "        \n",
    "        # Find the corresponding Monday shift with a start time of 00:00:00 for the same week\n",
    "        monday_shift = df[(df['MemberID'] == member_id) & \n",
    "                          (df['Scheduled_Day'] == 'Monday') & \n",
    "                          (df['Start_DateTime'].dt.time == datetime.strptime(\"00:00:00\", \"%H:%M:%S\").time())]\n",
    "        print(monday_shift)\n",
    "        \n",
    "        if not monday_shift.empty:\n",
    "            # Get the time of the Monday shift\n",
    "            monday_start_time = monday_shift.iloc[0]['End_DateTime'].time()\n",
    "            print(monday_start_time)\n",
    "\n",
    "            \n",
    "            # Update the Sunday shift's end time to the same date but the time of the Monday shift\n",
    "            new_end_datetime = shift['End_DateTime'].replace(hour=monday_start_time.hour, \n",
    "                                                             minute=monday_start_time.minute, \n",
    "                                                             second=monday_start_time.second, \n",
    "                                                             microsecond=0)\n",
    "            print(new_end_datetime)\n",
    "\n",
    "            # Adjust the date to the next day if the updated end time is before or equal to the original end time\n",
    "#             if new_end_datetime <= shift['End_DateTime']:\n",
    "#                 new_end_datetime = new_end_datetime + timedelta(days=1)\n",
    "            \n",
    "            # Set the updated end datetime\n",
    "            df.at[idx, 'End_DateTime'] = new_end_datetime\n",
    "            \n",
    "            # Recalculate Shift_Length and ShiftMinutes\n",
    "            df.at[idx, 'Shift_Length'] = (new_end_datetime - shift['Start_DateTime']).total_seconds()\n",
    "            df.at[idx, 'ShiftMinutes'] = df.at[idx, 'Shift_Length'] / 60\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Apply the adjustment\n",
    "df = adjust_sunday_shift(df)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "consolidated_df = df\n",
    "consolidated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont use agents with PTO for scheduled day\n",
    "pto_Scheduled = \"\"\" get your pto\n",
    "\n",
    "\"\"\"\n",
    "pto_Scheduled = pto_Scheduled % (start_date)    \n",
    "pto_Scheduled = pd.read_sql(pto_Scheduled, focus_db)\n",
    "\n",
    "pto_Scheduled['MemberID'] = pto_Scheduled['MemberID'].astype(int)\n",
    "pto_Scheduled['Scheduled_Date'] = pd.to_datetime(pto_Scheduled['Scheduled_Date']).dt.date\n",
    "consolidated_df['MemberID'] = consolidated_df['MemberID'].astype(int)\n",
    "consolidated_df['Scheduled_Date'] = pd.to_datetime(consolidated_df['Scheduled_Date']).dt.date\n",
    "\n",
    "PTO_Check = consolidated_df.merge(pto_Scheduled, on=['MemberID','Scheduled_Date'], how='left')\n",
    "PTO_Check.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "PTO_Check['PTO Scheduled'] = np.where(PTO_Check['PTO Mins'] > 0 ,'Y','N')\n",
    "Schedule_Agents = PTO_Check[PTO_Check['PTO Scheduled']=='N']\n",
    "\n",
    "PTO_ignore_schedule = PTO_Check[PTO_Check['PTO Scheduled']=='Y']\n",
    "print(PTO_ignore_schedule)\n",
    "\n",
    "Schedule_Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "focus_db = get_db_SS_focus()\n",
    "\n",
    "Insert_Start_SQL = 'LunchStart'\n",
    "Insert_Stop_SQL = 'LunchStop'\n",
    "Insert_Seconds_SQL = 'LunchSeconds'\n",
    "\n",
    "Insert_Reporting_Start = 'Lunch_start_window'\n",
    "Insert_Reporting_End = 'Lunch_end_window'\n",
    "Insert_Repoting_OnOff = 'Lunch'    \n",
    "\n",
    "\n",
    "report_RO_DB = Reporting_Read_Only()\n",
    "shift_Reporting_Sql = \"\"\"\n",
    "select Shift_Length_hrs*60 as 'ShiftMinutes', \n",
    "48 as Time_start_window, %s as Time_end_window,\n",
    "%s as 'Lunch_Option',\n",
    "(case when %s = 'Y' then 30 else 0 end) as 'Expected_Lunch_Time' \n",
    "from workforce.wfm_break_lunch wbl \"\"\"\n",
    "\n",
    "shift_Reporting_Sql = shift_Reporting_Sql % (Insert_Reporting_End,Insert_Repoting_OnOff,Insert_Repoting_OnOff)\n",
    "\n",
    "\n",
    "lunch_pd = pd.read_sql(shift_Reporting_Sql, report_RO_DB) \n",
    "lunch_pd\n",
    "# Merge lunch data with Schedule_Agents shifts\n",
    "agents_lunch_assign = pd.merge(Schedule_Agents, lunch_pd, how='left', on='ShiftMinutes')\n",
    "agents_lunch_assign['Time_start_window'].fillna(0, inplace=True)\n",
    "agents_lunch_assign['Time_end_window'].fillna(0, inplace=True)\n",
    "agents_lunch_assign['Lunch_Option'].fillna('N', inplace=True)\n",
    "\n",
    "\n",
    "#Override preset lunch duration\n",
    "report_RO_DB = Reporting_Read_Only()\n",
    "Block_Sch_Override = \"\"\"\n",
    "select MemberID, Lunch_Duration, Lunch_Duration_Min \n",
    "from workforce.blocksch_member_settings \n",
    "where Lunch_Duration = 'Y'\n",
    "\"\"\"\n",
    "Block_Sch_Override = pd.read_sql(Block_Sch_Override, report_RO_DB)\n",
    "agents_lunch_assign = pd.merge(agents_lunch_assign, Block_Sch_Override, on=['MemberID'],how='left')\n",
    "agents_lunch_assign['Lunch_Duration'].replace(np.nan,\"N\",inplace=True)\n",
    "agents_lunch_assign['Expected_Lunch_Time'] = np.where(agents_lunch_assign['Lunch_Duration'] == 'Y', agents_lunch_assign['Lunch_Duration_Min'],agents_lunch_assign['Expected_Lunch_Time'])\n",
    "agents_lunch_assign = agents_lunch_assign.fillna(0)\n",
    "agents_lunch_assign['Expected_Lunch_Time']  = agents_lunch_assign['Expected_Lunch_Time'].astype(int)\n",
    "\n",
    "agents_lunch_assign = agents_lunch_assign.drop(['Lunch_Duration', 'Lunch_Duration_Min'], axis=1)\n",
    "\n",
    "\n",
    "# Maintain a list of recently assigned lunch start times\n",
    "last_parameter_list = []\n",
    "max_round_robins = 3  # Maximum number of recent values to remember\n",
    "\n",
    "def generate_lunch_start(start_dt, end_dt, start_window, end_window, lunch_option, overnight_flag,lunch_duration,memberid):\n",
    "    if lunch_option == 'N':\n",
    "        return None, None\n",
    "\n",
    "    shift_duration = (end_dt - start_dt).total_seconds()\n",
    "    start_seconds = start_window * (shift_duration / 100)\n",
    "    end_seconds = end_window * (shift_duration / 100)\n",
    "\n",
    "    start_time = start_dt + timedelta(seconds=start_seconds)\n",
    "    end_time = start_dt + timedelta(seconds=end_seconds)\n",
    "\n",
    "    # Ensure that lunch start time is within start and end window\n",
    "    duration_seconds = (lunch_duration*60)\n",
    "\n",
    "    if((end_seconds - duration_seconds - start_seconds) <0):\n",
    "        start_seconds = start_seconds - 900\n",
    "        \n",
    "        if((end_seconds - duration_seconds - start_seconds) <0):\n",
    "            end_seconds = end_seconds + 900\n",
    "\n",
    "    lunch_start_seconds = np.random.randint(start_seconds, end_seconds - duration_seconds)\n",
    "\n",
    "    lunch_start = start_dt + timedelta(seconds=lunch_start_seconds)\n",
    "    lunch_end = lunch_start + timedelta(minutes=lunch_duration)  # Ensuring exact 30-minute duration\n",
    "\n",
    "    # Adjust if the 30-minute lunch exceeds the end of the window\n",
    "    if lunch_end > end_time:\n",
    "        lunch_start = end_time - timedelta(minutes=lunch_duration)\n",
    "        lunch_end = end_time\n",
    "\n",
    "    # Collision handling\n",
    "    lunch_start_seconds = int((lunch_start - start_dt).total_seconds())\n",
    "    while lunch_start_seconds in last_parameter_list:\n",
    "        lunch_start_seconds = (lunch_start_seconds + 900) % 86400\n",
    "        lunch_start = start_dt + timedelta(seconds=lunch_start_seconds)\n",
    "        lunch_end = lunch_start + timedelta(minutes=lunch_duration)\n",
    "        if lunch_end > end_time:\n",
    "            break\n",
    "\n",
    "    # Append to the list and maintain its length\n",
    "    last_parameter_list.append(lunch_start_seconds)\n",
    "    if len(last_parameter_list) > max_round_robins:\n",
    "        last_parameter_list.pop(0)\n",
    "#     print (lunch_start,\"Lunchstart\")\n",
    "\n",
    "    lunch_start = round_to_nearest_interval(lunch_start,overnight_flag)\n",
    "    lunch_end = lunch_start + timedelta(minutes=lunch_duration)\n",
    "\n",
    "    # Final boundary check to ensure times remain within start and end window\n",
    "    if lunch_start < start_time:\n",
    "        lunch_start = start_time\n",
    "        lunch_end = lunch_start + timedelta(minutes=lunch_duration)\n",
    "    if lunch_end > end_time:\n",
    "        lunch_end = end_time\n",
    "        lunch_start = lunch_end - timedelta(minutes=lunch_duration)\n",
    "        \n",
    "    lunch_start = round_to_nearest_interval(lunch_start,overnight_flag)\n",
    "    lunch_end = lunch_start + timedelta(minutes=lunch_duration)\n",
    "\n",
    "    return lunch_start, lunch_end\n",
    "\n",
    "\n",
    "def round_to_nearest_interval(dt, overnight_flag):\n",
    "    if overnight_flag == 'Y':\n",
    "        interval = 30  # Round to nearest 30 minutes\n",
    "    else:\n",
    "        interval = 15  # Round to nearest 15 minutes\n",
    "    \n",
    "\n",
    "    # Calculate the nearest 15-minute interval\n",
    "    nearest_multiple_of_15 = round(dt.minute / 15) * 15\n",
    "    \n",
    "    # Adjust the datetime based on the calculated interval\n",
    "    rounded_dt = dt.replace(minute=nearest_multiple_of_15 % 60, second=0, microsecond=0)\n",
    "    \n",
    "    # Handle overflow to the next hour if rounding to 60 minutes\n",
    "    if nearest_multiple_of_15 == 60:\n",
    "        rounded_dt += timedelta(hours=1)\n",
    "    \n",
    "    return rounded_dt\n",
    "\n",
    "\n",
    "# Define function to process each row\n",
    "def process_row_for_lunch(row):\n",
    "    lunch_start, lunch_end = generate_lunch_start(\n",
    "        row['Start_DateTime'], row['End_DateTime'],\n",
    "        row['Time_start_window'], row['Time_end_window'],\n",
    "        row['Lunch_Option'], row['Overnight'],row['Expected_Lunch_Time'],\n",
    "        row['MemberID']\n",
    "    )\n",
    "    \n",
    "    # Calculate Lunch_Seconds if both start and end times are not None\n",
    "    lunch_seconds = (lunch_end - lunch_start).total_seconds() if lunch_start and lunch_end else 0\n",
    "    \n",
    "    return pd.Series({\n",
    "        'MemberID': row['MemberID'],\n",
    "        'Name': row['Name'],\n",
    "        'Department': row['Department'],\n",
    "        'Scheduled_Date': row['Scheduled_Date'],\n",
    "        'Scheduled_Day': row['Scheduled_Day'],\n",
    "        'Start_DateTime': row['Start_DateTime'],\n",
    "        'End_DateTime': row['End_DateTime'],\n",
    "        'Shift_Length': row['Shift_Length'],\n",
    "        'ShiftMinutes': row['ShiftMinutes'],\n",
    "        'Lunch_Option': row['Lunch_Option'],\n",
    "        'Lunch_Start_DateTime': lunch_start,\n",
    "        'Lunch_End_DateTime': lunch_end,\n",
    "        'Lunch_Seconds': lunch_seconds,\n",
    "        'Overnight': row['Overnight'],\n",
    "    })\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "lunch_assignments_df = agents_lunch_assign.apply(process_row_for_lunch, axis=1)\n",
    "\n",
    "# Convert Scheduled_Date column to datetime if it's not already\n",
    "lunch_assignments_df['Scheduled_DateTime'] = pd.to_datetime(lunch_assignments_df['Scheduled_Date'])\n",
    "\n",
    "# Calculate Start and End in seconds since midnight\n",
    "lunch_assignments_df['Start'] = (lunch_assignments_df['Start_DateTime'] - lunch_assignments_df['Scheduled_DateTime']).dt.total_seconds()\n",
    "lunch_assignments_df['End'] = (lunch_assignments_df['End_DateTime'] - lunch_assignments_df['Scheduled_DateTime']).dt.total_seconds()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "lunch_assignments_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insert_Start_SQL = 'BreakAStart'\n",
    "Insert_Stop_SQL = 'BreakAStop'\n",
    "Insert_Seconds_SQL = 'BreakASeconds'\n",
    "\n",
    "Insert_Reporting_Start = 'BreakA_Start'\n",
    "Insert_Reporting_End = 'BreakA_End'\n",
    "Insert_Repoting_OnOff = 'BreakA'    \n",
    "\n",
    "\n",
    "report_RO_DB = Reporting_Read_Only()\n",
    "shift_Reporting_Sql = \"\"\"\n",
    "select Shift_Length_hrs*60 as 'ShiftMinutes', \n",
    "%s as Time_start_window, %s as Time_end_window,\n",
    "%s as 'BreakA_Option',\n",
    "(case when %s = 'Y' then 15 else 0 end) as 'Expected_BreakA_Time' \n",
    "from workforce.wfm_break_lunch wbl \"\"\"\n",
    "\n",
    "shift_Reporting_Sql = shift_Reporting_Sql % (Insert_Reporting_Start,Insert_Reporting_End,Insert_Repoting_OnOff,Insert_Repoting_OnOff)\n",
    "\n",
    "BreakA_pd = pd.read_sql(shift_Reporting_Sql, report_RO_DB) \n",
    "\n",
    "Agents_BreakA_Assign = pd.merge(lunch_assignments_df,BreakA_pd,how='left',left_on='ShiftMinutes',right_on='ShiftMinutes')\n",
    "Agents_BreakA_Assign['Time_start_window'].fillna(0, inplace=True)\n",
    "Agents_BreakA_Assign['Time_end_window'].fillna(0, inplace=True)\n",
    "Agents_BreakA_Assign['BreakA_Option'].fillna('N', inplace=True)\n",
    "\n",
    "\n",
    "#Override preset Break  duration\n",
    "report_RO_DB = Reporting_Read_Only()\n",
    "Block_Sch_Override = \"\"\"\n",
    "select MemberID, breakA_Duration, breakA_Duration_Min \n",
    "from workforce.blocksch_member_settings \n",
    "where breakA_Duration = 'Y'\n",
    "\"\"\"\n",
    "Block_Sch_Override = pd.read_sql(Block_Sch_Override, report_RO_DB)\n",
    "Agents_BreakA_Assign = pd.merge(Agents_BreakA_Assign, Block_Sch_Override, on=['MemberID'],how='left')\n",
    "Agents_BreakA_Assign['breakA_Duration'].replace(np.nan,\"N\",inplace=True)\n",
    "Agents_BreakA_Assign['Expected_BreakA_Time'] = np.where(Agents_BreakA_Assign['breakA_Duration'] == 'Y', Agents_BreakA_Assign['breakA_Duration_Min'],Agents_BreakA_Assign['Expected_BreakA_Time'])\n",
    "Agents_BreakA_Assign = Agents_BreakA_Assign.drop(['breakA_Duration', 'breakA_Duration_Min'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Maintain a list of recently assigned BreakA start times\n",
    "last_breakA_parameter_list = []\n",
    "max_breakA_round_robins = 3  # Maximum number of recent values to remember for BreakA\n",
    "\n",
    "def generate_BreakA_start(start_dt, end_dt, start_window, end_window, break_option,breakA_duration):\n",
    "    if break_option == 'N':\n",
    "        return None, None\n",
    "\n",
    "    # Calculate the shift duration in seconds\n",
    "    shift_duration = (end_dt - start_dt).total_seconds()\n",
    "\n",
    "    duration_seconds = (breakA_duration*60)\n",
    "    \n",
    "    # Calculate start and end of the window in seconds\n",
    "    start_seconds = start_window * (shift_duration / 100)\n",
    "    end_seconds = end_window * (shift_duration / 100)\n",
    "    print(start_dt)\n",
    "    print(end_dt)\n",
    "\n",
    "    print(start_seconds)\n",
    "    print(end_seconds)\n",
    "\n",
    "\n",
    "    # Calculate the start and end time of the window\n",
    "    start_time = start_dt + timedelta(seconds=start_seconds)\n",
    "    end_time = start_dt + timedelta(seconds=end_seconds)\n",
    "    \n",
    "    # Generate a random BreakA start time within the window\n",
    "    breakA_start = start_time + timedelta(seconds=np.random.randint(0, int(end_seconds - start_seconds)))\n",
    "    \n",
    "    # Adjust for collisions\n",
    "    breakA_start_seconds = breakA_start.hour * 3600 + breakA_start.minute * 60\n",
    "    while breakA_start_seconds in last_breakA_parameter_list:\n",
    "        breakA_start_seconds = (breakA_start_seconds + 900) % 86400  # Shift by 15 minutes\n",
    "        breakA_start = breakA_start.replace(hour=0, minute=0, second=0) + timedelta(seconds=breakA_start_seconds)\n",
    "    \n",
    "    # Update the list of recent values\n",
    "    last_breakA_parameter_list.append(breakA_start_seconds)\n",
    "    if len(last_breakA_parameter_list) > max_breakA_round_robins:\n",
    "        last_breakA_parameter_list.pop(0)\n",
    "    \n",
    "    # Round to nearest 15 minutes\n",
    "    breakA_start = round_to_nearest_15_minutes(breakA_start)\n",
    "    breakA_end = breakA_start + timedelta(minutes=breakA_duration)\n",
    "    \n",
    "    # Adjust if BreakA crosses midnight or end of the shift\n",
    "    if breakA_end > end_dt:\n",
    "        breakA_end = end_dt\n",
    "        breakA_start = breakA_end - timedelta(minutes=breakA_duration)\n",
    "\n",
    "    return breakA_start, breakA_end\n",
    "\n",
    "# Define round_to_nearest_15_minutes function\n",
    "def round_to_nearest_15_minutes(dt):\n",
    "    minute = (dt.minute // 15) * 15\n",
    "    return dt.replace(minute=minute, second=0, microsecond=0)\n",
    "\n",
    "# Apply function to assign BreakA\n",
    "def process_row_for_breakA(row):\n",
    "    breakA_start, breakA_end = generate_BreakA_start(\n",
    "        row['Start_DateTime'], row['End_DateTime'],\n",
    "        row['Time_start_window'], row['Time_end_window'],\n",
    "        row['BreakA_Option'] ,row['Expected_BreakA_Time']\n",
    "    )\n",
    "    \n",
    "    # Calculate BreakA_Seconds if both start and end times are not None\n",
    "    breakA_seconds = (breakA_end - breakA_start).total_seconds() if breakA_start and breakA_end else 0\n",
    "    \n",
    "    return pd.Series({\n",
    "        'MemberID': row['MemberID'],\n",
    "        'Name': row['Name'],\n",
    "        'Department': row['Department'],\n",
    "        'Scheduled_Date': row['Scheduled_Date'],\n",
    "        'Scheduled_Day': row['Scheduled_Day'],\n",
    "        'Start_DateTime': row['Start_DateTime'],\n",
    "        'End_DateTime': row['End_DateTime'],\n",
    "        'Shift_Length': row['Shift_Length'],\n",
    "        'ShiftMinutes': row['ShiftMinutes'],\n",
    "        'Lunch_Option':row['Lunch_Option'],\n",
    "\n",
    "        'Lunch_Start_DateTime': row['Lunch_Start_DateTime'],\n",
    "        'Lunch_End_DateTime': row['Lunch_End_DateTime'],\n",
    "        'Lunch_Seconds': row['Lunch_Seconds'],\n",
    "        'BreakA_Option':row['BreakA_Option'],\n",
    "\n",
    "        'BreakA_Start_DateTime': breakA_start,\n",
    "        'BreakA_End_DateTime': breakA_end,\n",
    "        'BreakA_Seconds': breakA_seconds,\n",
    "        'Overnight' :row['Overnight'],\n",
    "\n",
    "    })\n",
    "\n",
    "# Apply the function to each row in the DataFrame\n",
    "BreakA_assignments_df = Agents_BreakA_Assign.apply(process_row_for_breakA, axis=1)\n",
    "\n",
    "# Convert Scheduled_Date column to datetime if it's not already\n",
    "BreakA_assignments_df['Scheduled_DateTime'] = pd.to_datetime(BreakA_assignments_df['Scheduled_Date'])\n",
    "\n",
    "# Calculate Start and End in seconds since midnight\n",
    "BreakA_assignments_df['Start'] = (BreakA_assignments_df['Start_DateTime'] - BreakA_assignments_df['Scheduled_DateTime']).dt.total_seconds()\n",
    "BreakA_assignments_df['End'] = (BreakA_assignments_df['End_DateTime'] - BreakA_assignments_df['Scheduled_DateTime']).dt.total_seconds()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "BreakA_assignments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insert_Start_SQL = 'BreakBStart'\n",
    "Insert_Stop_SQL = 'BreakBStop'\n",
    "Insert_Seconds_SQL = 'BreakBSeconds'\n",
    "\n",
    "Insert_Reporting_Start = 'BreakB_Start'\n",
    "Insert_Reporting_End = 'BreakB_End'\n",
    "Insert_Repoting_OnOff = 'BreakB'    \n",
    "\n",
    "\n",
    "report_RO_DB = Reporting_Read_Only()\n",
    "shift_Reporting_Sql = \"\"\"\n",
    "select Shift_Length_hrs*60 as 'ShiftMinutes', \n",
    "%s as Time_start_window, %s as Time_end_window,\n",
    "%s as 'BreakB_Option',\n",
    "(case when %s = 'Y' then 15 else 0 end) as 'Expected_BreakB_Time' \n",
    "from workforce.wfm_break_lunch wbl \"\"\"\n",
    "\n",
    "shift_Reporting_Sql = shift_Reporting_Sql % (Insert_Reporting_Start,Insert_Reporting_End,Insert_Repoting_OnOff,Insert_Repoting_OnOff)\n",
    "\n",
    "BreakB_pd = pd.read_sql(shift_Reporting_Sql, report_RO_DB) \n",
    "\n",
    "Agents_BreakB_Assign = pd.merge(BreakA_assignments_df,BreakB_pd,how='left',left_on='ShiftMinutes',right_on='ShiftMinutes')\n",
    "# Agents_BreakB_Assign.replace(np.nan,0,inplace=True)\n",
    "Agents_BreakB_Assign['Time_start_window'].fillna(0, inplace=True)\n",
    "Agents_BreakB_Assign['Time_end_window'].fillna(0, inplace=True)\n",
    "Agents_BreakB_Assign['BreakB_Option'].fillna('N', inplace=True)\n",
    "\n",
    "\n",
    "#Override preset Break  duration\n",
    "report_RO_DB = Reporting_Read_Only()\n",
    "Block_Sch_Override = \"\"\"\n",
    "select MemberID, breakB_Duration, breakB_Duration_Min \n",
    "from workforce.blocksch_member_settings \n",
    "where breakB_Duration = 'Y'\n",
    "\"\"\"\n",
    "Block_Sch_Override = pd.read_sql(Block_Sch_Override, report_RO_DB)\n",
    "Agents_BreakB_Assign = pd.merge(Agents_BreakB_Assign, Block_Sch_Override, on=['MemberID'],how='left')\n",
    "Agents_BreakB_Assign['breakB_Duration'].replace(np.nan,\"N\",inplace=True)\n",
    "Agents_BreakB_Assign['Expected_BreakB_Time'] = np.where(Agents_BreakB_Assign['breakB_Duration'] == 'Y', Agents_BreakB_Assign['breakB_Duration_Min'],Agents_BreakB_Assign['Expected_BreakB_Time'])\n",
    "Agents_BreakB_Assign = Agents_BreakB_Assign.drop(['breakB_Duration', 'breakB_Duration_Min'], axis=1)\n",
    "\n",
    "# Maintain a list of recently assigned BreakB start times\n",
    "last_breakB_parameter_list = []\n",
    "max_breakB_round_robins = 3  # Maximum number of recent values to remember for BreakB\n",
    "\n",
    "def generate_breakB_start(start_dt, end_dt, start_window, end_window, breakB_option,breakB_duration):\n",
    "    if breakB_option == 'N':\n",
    "        return None, None\n",
    "\n",
    "    duration_seconds = (breakB_duration*60)\n",
    "\n",
    "    shift_duration = (end_dt - start_dt).total_seconds()\n",
    "    start_seconds = start_window * (shift_duration / 100)\n",
    "    end_seconds = end_window * (shift_duration / 100)\n",
    "    \n",
    "    start_time = start_dt + timedelta(seconds=start_seconds)\n",
    "    end_time = start_dt + timedelta(seconds=end_seconds)\n",
    "    \n",
    "    # Generate a random BreakB start time\n",
    "    breakB_start = start_time + timedelta(seconds=np.random.randint(0, int(end_seconds - start_seconds)))\n",
    "    \n",
    "    # Adjust for collisions\n",
    "    breakB_start_seconds = breakB_start.hour * 3600 + breakB_start.minute * 60\n",
    "    while breakB_start_seconds in last_breakB_parameter_list:\n",
    "        breakB_start_seconds = (breakB_start_seconds + 900) % 86400  # Shift by 15 minutes\n",
    "        breakB_start = breakB_start.replace(hour=0, minute=0, second=0) + timedelta(seconds=breakB_start_seconds)\n",
    "    \n",
    "    last_breakB_parameter_list.append(breakB_start_seconds)\n",
    "    if len(last_breakB_parameter_list) > max_breakB_round_robins:\n",
    "        last_breakB_parameter_list.pop(0)\n",
    "    \n",
    "    breakB_start = round_to_nearest_15_minutes(breakB_start)  # Round to nearest 15 minutes\n",
    "    breakB_end = breakB_start + timedelta(minutes=breakB_duration)\n",
    "    \n",
    "    # Adjust if BreakB crosses midnight or end of the shift\n",
    "    if breakB_end > end_dt:\n",
    "        breakB_end = end_dt\n",
    "        breakB_start = breakB_end - timedelta(minutes=breakB_duration)\n",
    "\n",
    "    return breakB_start, breakB_end\n",
    "\n",
    "# Function to round BreakB start time to the nearest 15 minutes\n",
    "def round_to_nearest_15_minutes(dt):\n",
    "    minute = (dt.minute // 15) * 15\n",
    "    return dt.replace(minute=minute, second=0, microsecond=0)\n",
    "\n",
    "# Apply function to assign BreakB\n",
    "breakB_assignments = []\n",
    "\n",
    "for index, row in Agents_BreakB_Assign.iterrows():\n",
    "    breakB_start, breakB_end = generate_breakB_start(\n",
    "        row['Start_DateTime'], row['End_DateTime'],\n",
    "        row['Time_start_window'], row['Time_end_window'],\n",
    "        row['BreakB_Option'],row['Expected_BreakB_Time']  # Assuming there's a column for BreakB options\n",
    "    )\n",
    "    \n",
    "    breakB_assignments.append({\n",
    "        'MemberID': row['MemberID'],\n",
    "        'Name': row['Name'],\n",
    "        'Department': row['Department'],\n",
    "        'Scheduled_Date': row['Scheduled_Date'],\n",
    "        'Scheduled_Day': row['Scheduled_Day'],\n",
    "        'Start_DateTime': row['Start_DateTime'],\n",
    "        'End_DateTime': row['End_DateTime'],\n",
    "        'Shift_Length': row['Shift_Length'],\n",
    "        'ShiftMinutes': row['ShiftMinutes'],\n",
    "        'Lunch_Option':row['Lunch_Option'],\n",
    "        'Lunch_Start_DateTime' : row['Lunch_Start_DateTime'],\n",
    "        'Lunch_End_DateTime' : row['Lunch_End_DateTime'],\n",
    "        'Lunch_Seconds':row['Lunch_Seconds'],\n",
    "        'BreakA_Option':row['BreakA_Option'],\n",
    "        'BreakA_Start_DateTime':row['BreakA_Start_DateTime'],\n",
    "        'BreakA_End_DateTime':row['BreakA_End_DateTime'],\n",
    "        'BreakA_Seconds':row['BreakA_Seconds'],   \n",
    "        'BreakB_Option':row['BreakB_Option'],\n",
    "        'BreakB_Start_DateTime': breakB_start,\n",
    "        'BreakB_End_DateTime': breakB_end,\n",
    "        'BreakB_Seconds': (breakB_end - breakB_start).total_seconds() if breakB_start and breakB_end else 0,\n",
    "        'Overnight' :row['Overnight'],\n",
    "\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "breakB_assignments_df = pd.DataFrame(breakB_assignments)\n",
    "breakB_assignments_df['Scheduled_DateTime'] = pd.to_datetime(breakB_assignments_df['Scheduled_Date'])\n",
    "\n",
    "breakB_assignments_df['Start'] = (breakB_assignments_df['Start_DateTime'] - breakB_assignments_df['Scheduled_DateTime']).dt.total_seconds()\n",
    "breakB_assignments_df['End'] = (breakB_assignments_df['End_DateTime'] - breakB_assignments_df['Scheduled_DateTime']).dt.total_seconds()\n",
    "\n",
    "breakB_assignments_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_assigned_shifts = breakB_assignments_df\n",
    "All_assigned_shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns\n",
    "datetime_cols = ['Start_DateTime', 'End_DateTime', 'Lunch_Start_DateTime', 'Lunch_End_DateTime', \n",
    "                  'BreakA_Start_DateTime', 'BreakA_End_DateTime', 'BreakB_Start_DateTime', 'BreakB_End_DateTime']\n",
    "All_assigned_shifts[datetime_cols] = All_assigned_shifts[datetime_cols].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "# Initialize list for split data\n",
    "split_data = []\n",
    "\n",
    "# Split shifts\n",
    "for idx, row in All_assigned_shifts.iterrows():\n",
    "    if row['Overnight'] == 'Y':\n",
    "        print(idx)\n",
    "        print(row)\n",
    "        # Calculate the split time (midnight)\n",
    "        split_time = (row['Start_DateTime'] + pd.DateOffset(days=1)).normalize()\n",
    "\n",
    "        \n",
    "        # First part of the shift\n",
    "        first_part = row.copy()\n",
    "        first_part['End_DateTime'] = split_time\n",
    "        first_part['Shift_Length'] = (split_time - row['Start_DateTime']).total_seconds()\n",
    "        first_part['ShiftMinutes'] = first_part['Shift_Length'] / 60\n",
    "        first_part['Start_DateTime'] = row['Start_DateTime']\n",
    "        first_part['Scheduled_Date'] = row['Scheduled_Date']\n",
    "        first_part['Scheduled_Day'] = row['Scheduled_Day']\n",
    "        \n",
    "        # Second part of the shift\n",
    "        second_part = row.copy()\n",
    "        second_part['Start_DateTime'] = split_time\n",
    "        second_part['End_DateTime'] = row['End_DateTime']\n",
    "        second_part['Shift_Length'] = (row['End_DateTime'] - split_time).total_seconds()\n",
    "        second_part['ShiftMinutes'] = second_part['Shift_Length'] / 60\n",
    "        second_part['Scheduled_Date'] = (pd.Timestamp(row['Scheduled_Date']) + pd.DateOffset(days=1)).strftime('%Y-%m-%d')\n",
    "        second_part['Scheduled_Day'] = (pd.Timestamp(row['Scheduled_Date']) + pd.DateOffset(days=1)).day_name()\n",
    "\n",
    "        # Allocate lunch and breaks\n",
    "        for col in ['Lunch', 'BreakA', 'BreakB']:\n",
    "            start_col = f'{col}_Start_DateTime'\n",
    "            end_col = f'{col}_End_DateTime'\n",
    "            start_dates = row[start_col].date() if not pd.isna(row[start_col]) else None\n",
    "            end_dates = row[end_col].date() if not pd.isna(row[end_col]) else None\n",
    "\n",
    "            # Allocate lunch and breaks for the first part\n",
    "            if start_dates == row['Start_DateTime'].date() and end_dates and end_dates <= split_time.date():\n",
    "                first_part[start_col] = row[start_col]\n",
    "                first_part[end_col] = row[end_col]\n",
    "                first_part[f'{col}_Seconds'] = row[f'{col}_Seconds']\n",
    "            else:\n",
    "                first_part[start_col] = None\n",
    "                first_part[end_col] = None\n",
    "                first_part[f'{col}_Seconds'] = 0\n",
    "\n",
    "            # Allocate lunch and breaks for the second part\n",
    "            if start_dates == split_time.date():\n",
    "                second_part[start_col] = row[start_col] if not pd.isna(row[start_col]) else None\n",
    "                second_part[end_col] = row[end_col] if not pd.isna(row[end_col]) else None\n",
    "                second_part[f'{col}_Seconds'] = row[f'{col}_Seconds']\n",
    "            else:\n",
    "                second_part[start_col] = None\n",
    "                second_part[end_col] = None\n",
    "                second_part[f'{col}_Seconds'] = 0\n",
    "\n",
    "        split_data.append(first_part)\n",
    "        split_data.append(second_part)\n",
    "    else:\n",
    "        split_data.append(row)\n",
    "\n",
    "# Create new DataFrame\n",
    "split_df = pd.DataFrame(split_data)\n",
    "\n",
    "# Reset index\n",
    "split_df.reset_index(drop=True, inplace=True)\n",
    "split_df = split_df[split_df['Shift_Length']!=0]\n",
    "split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Att_sql=\"\"\"\n",
    "SELECT MemberID, ProjectID, TypeID FROM SS_focus.MemberTraining mt \n",
    "where Ranking = 1\n",
    "\"\"\"\n",
    "Training_Att_sql = pd.read_sql(Training_Att_sql, focus_db)\n",
    "\n",
    "Agent_Data_Only_Final = pd.merge(split_df,Training_Att_sql,on=['MemberID'],how='left')\n",
    "Agent_Data_Only_Final = Agent_Data_Only_Final[Agent_Data_Only_Final['ProjectID'].notnull()]\n",
    "Agent_Data_Only_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lunch_assignments_df.to_excel(\"lunch_assignments_df.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_RO_DB = Reporting_Read_Only()\n",
    "Block_Sch_Override = \"\"\"\n",
    "select * from workforce.blocksch_member_settings \"\"\"\n",
    "Block_Sch_Override = pd.read_sql(Block_Sch_Override, report_RO_DB)\n",
    "\n",
    "WFM_Agent_Override = pd.merge(Agent_Data_Only_Final, Block_Sch_Override, on=['MemberID'],how='left')\n",
    "\n",
    "WFM_Agent_Override['Override_breakA'].replace(np.nan,\"N\",inplace=True)\n",
    "WFM_Agent_Override['Override_breakB'].replace(np.nan,\"N\",inplace=True)\n",
    "WFM_Agent_Override['Override_Lunch'].replace(np.nan,\"N\",inplace=True)\n",
    "WFM_Agent_Override['Override_FullSchedule'].replace(np.nan,\"N\",inplace=True)\n",
    "\n",
    "WFM_Agent_Override['Lunch_Option'] = np.where(WFM_Agent_Override['Override_Lunch'] == 'Y', \"N\",WFM_Agent_Override['Lunch_Option'])\n",
    "WFM_Agent_Override['Lunch_Seconds'] = np.where(WFM_Agent_Override['Override_Lunch'] == 'Y', 0,WFM_Agent_Override['Lunch_Seconds'])\n",
    "WFM_Agent_Override['BreakA_Option'] = np.where(WFM_Agent_Override['Override_breakA'] == 'Y', \"N\",WFM_Agent_Override['BreakA_Option'])\n",
    "WFM_Agent_Override['BreakA_Seconds'] = np.where(WFM_Agent_Override['Override_breakA'] == 'Y', 0,WFM_Agent_Override['BreakA_Seconds'])\n",
    "WFM_Agent_Override['BreakB_Option'] = np.where(WFM_Agent_Override['Override_breakB'] == 'Y', \"N\",WFM_Agent_Override['BreakB_Option'])\n",
    "WFM_Agent_Override['BreakB_Seconds'] = np.where(WFM_Agent_Override['Override_breakB'] == 'Y', 0,WFM_Agent_Override['BreakB_Seconds'])\n",
    "\n",
    "WFM_Agent_Override = WFM_Agent_Override[WFM_Agent_Override['Override_FullSchedule'] != 'Y'].reset_index(drop=True)       \n",
    "\n",
    "\n",
    "check_Already_Scheduled = \"\"\"    SELECT \n",
    "ess.id as 'ShiftID',\n",
    "m.id as 'MemberID', ShiftStart,ShiftStop\n",
    "FROM SS_focus.EmployeeScheduleShift ess\n",
    "join SS_focus.Member m on m.id = ess.MemberID \n",
    "where Date(ShiftStart) >= '%s' \n",
    "\"\"\"\n",
    "check_Already_Scheduled = check_Already_Scheduled % (start_date)    \n",
    "check_Already_Scheduled = pd.read_sql(check_Already_Scheduled, focus_db)\n",
    "check_Already_Scheduled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Schedule and overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = WFM_Agent_Override\n",
    "df2 = check_Already_Scheduled\n",
    "# Convert relevant columns to datetime\n",
    "df1['Start_DateTime'] = pd.to_datetime(df1['Start_DateTime'])\n",
    "df1['End_DateTime'] = pd.to_datetime(df1['End_DateTime'])\n",
    "df2['ShiftStart'] = pd.to_datetime(df2['ShiftStart'])\n",
    "df2['ShiftStop'] = pd.to_datetime(df2['ShiftStop'])\n",
    "\n",
    "# Calculate duration of shifts\n",
    "df1['Duration'] = df1['End_DateTime'] - df1['Start_DateTime']\n",
    "df2['Duration'] = df2['ShiftStop'] - df2['ShiftStart']\n",
    "\n",
    "# Initialize a DataFrame to hold the updated df1\n",
    "df1_updated = df1.copy()\n",
    "\n",
    "# Process each MemberID separately\n",
    "for member_id in df1_updated['MemberID'].unique():\n",
    "#     print (member_id)\n",
    "    # Filter shifts for this MemberID in both df1 and df2\n",
    "    df1_member = df1_updated[df1_updated['MemberID'] == member_id]\n",
    "    df2_member = df2[df2['MemberID'] == member_id]\n",
    "\n",
    "    # Iterate over each shift in df1_member\n",
    "    for idx1, row1 in df1_member.iterrows():\n",
    "        start1 = row1['Start_DateTime']\n",
    "        end1 = row1['End_DateTime']\n",
    "        duration1 = row1['Duration']\n",
    "        date1 = start1.date()  # Extract date part for checking daily shifts\n",
    "        \n",
    "        shift_id = None  # Initialize shift_id\n",
    "\n",
    "        exact_match_found = False\n",
    "        overlap_found = False\n",
    "        \n",
    "        for idx2, row2 in df2_member.iterrows():\n",
    "            start2 = row2['ShiftStart']\n",
    "            end2 = row2['ShiftStop']\n",
    "            duration2 = row2['Duration']\n",
    "            date2 = start2.date()  # Extract date part for checking daily shifts\n",
    "\n",
    "            # Check if both shifts are on the same day\n",
    "            if date1 == date2:\n",
    "                # Check for exact match\n",
    "                if start1 == start2 and end1 == end2 and duration1 == duration2:\n",
    "                    exact_match_found = True\n",
    "                    shift_id = row2['ShiftID']  # Assign ShiftID from df2\n",
    "                    break  # Stop checking once an exact match is found\n",
    "                \n",
    "                # Check for overlap: (Shift1 starts before Shift2 ends) and (Shift1 ends after Shift2 starts)\n",
    "                elif (start1 < end2) and (end1 > start2):\n",
    "                    overlap_found = True\n",
    "                    shift_id = row2['ShiftID']  # Assign ShiftID from df2 for overlapping shift\n",
    "\n",
    "        # Update df1_updated with ShiftID based on match status\n",
    "        if exact_match_found:\n",
    "            df1_updated.at[idx1, 'ShiftID'] = shift_id  # Use the exact ShiftID from df2\n",
    "        elif overlap_found and shift_id is not None:\n",
    "            df1_updated.at[idx1, 'ShiftID'] = shift_id  # Assign ShiftID if an overlap exists\n",
    "        else:\n",
    "            df1_updated.at[idx1, 'ShiftID'] = None  # No match or overlap found\n",
    "\n",
    "# Output or use df1_updated\n",
    "df1_updated['Already Scheduled'] = np.where(df1_updated['ShiftID'].notnull(),'Y','N')\n",
    "df1_updated = df1_updated[df1_updated['Already Scheduled'] != 'Y']\n",
    "df1_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Time if Break should be null\n",
    "df1_updated['Lunch_Seconds'] = np.where(df1_updated['Lunch_Option'] == 'N',0,df1_updated['Lunch_Seconds'] )\n",
    "df1_updated['BreakA_Seconds'] = np.where(df1_updated['BreakA_Option'] == 'N',0,df1_updated['BreakA_Seconds'] )\n",
    "df1_updated['BreakB_Seconds'] = np.where(df1_updated['BreakB_Option'] == 'N',0,df1_updated['BreakB_Seconds'] )\n",
    "\n",
    "df1_updated = df1_updated.reset_index(drop=True)\n",
    "\n",
    "Client_Schedule_Blocker = \"\"\"\n",
    "select distinct * from (   \n",
    "select Date_Blocked as 'Scheduled_Date', clientCode,  'Y' as 'Block_Date'\n",
    "from reporting.wfm_block_date wb\n",
    "where wb.clientCode is not null and wb.clientCode != \"\"\n",
    "union all\n",
    "select Date_Blocked as 'Scheduled_Date', clientCode,  'Y' as 'Block_Date'\n",
    "from workforce.wfm_block_date wa\n",
    "where wa.clientCode is not null and wa.clientCode != \"\"\n",
    ") A \"\"\"\n",
    "\n",
    "Client_Schedule_Blocker_pd = pd.read_sql(Client_Schedule_Blocker, report_RO_DB) \n",
    "Client_Schedule_Blocker_pd = Client_Schedule_Blocker_pd.drop_duplicates().reset_index(drop=True)\n",
    "sql=\"\"\"SELECT ID as 'ProjectID', Code as 'clientCode'\n",
    "FROM SS_focus.Project \n",
    "where active = 1\n",
    "\"\"\"\n",
    "Project_pd = pd.read_sql(sql, focus_db)\n",
    "\n",
    "Schedule_Blocker_pd = pd.merge(Client_Schedule_Blocker_pd,Project_pd, on=['clientCode'],how='left' )\n",
    "\n",
    "Schedule_Blocker_pd = Schedule_Blocker_pd[['Scheduled_Date','ProjectID','Block_Date']]\n",
    "\n",
    "Schedule_Blocker_pd['ProjectID'] = Schedule_Blocker_pd['ProjectID'].fillna(0).astype(int)\n",
    "\n",
    "# Test\n",
    "# new_row = {\n",
    "#     'Scheduled_Date': '2024-09-02',\n",
    "#     'ProjectID': 42,\n",
    "#     'Block_Date': 'Y'\n",
    "# }\n",
    "\n",
    "# # Append new row to the DataFrame\n",
    "# Schedule_Blocker_pd = Schedule_Blocker_pd.append(new_row, ignore_index=True)\n",
    "# Schedule_Blocker_pd\n",
    "\n",
    "Schedule_Blocker_pd['Scheduled_Date'] = Schedule_Blocker_pd['Scheduled_Date'].fillna(0).astype(str)\n",
    "df1_updated['Scheduled_Date'] = df1_updated['Scheduled_Date'].fillna(0).astype(str)\n",
    "Schedule_Blocker_pd['ProjectID'] = Schedule_Blocker_pd['ProjectID'].fillna(0).astype(str)\n",
    "df1_updated['ProjectID'] = df1_updated['ProjectID'].fillna(0).astype(str)\n",
    "Schedule_Blocker_pd['Block_Date'] = Schedule_Blocker_pd['Block_Date'].fillna(0).astype(str)\n",
    "\n",
    "Agents_Scheduled_Block = pd.merge(df1_updated,Schedule_Blocker_pd, on=['Scheduled_Date','ProjectID',],how='left')\n",
    "Agents_Scheduled_Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handles Block_date for Midnight shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Agents_Scheduled_Block\n",
    "\n",
    "# Convert to datetime\n",
    "df['Start_DateTime'] = pd.to_datetime(df['Start_DateTime'])\n",
    "df['End_DateTime'] = pd.to_datetime(df['End_DateTime'])\n",
    "df['Scheduled_Date'] = pd.to_datetime(df['Scheduled_Date'])\n",
    "\n",
    "# Sort by MemberID, Scheduled_Date, Start_DateTime to ensure the order\n",
    "df = df.sort_values(by=['MemberID', 'Scheduled_Date', 'Start_DateTime'])\n",
    "\n",
    "# Initialize a list to collect all cleaned dataframes\n",
    "cleaned_dfs = []\n",
    "\n",
    "# Get the list of unique MemberIDs\n",
    "member_ids = df['MemberID'].unique()\n",
    "\n",
    "for member_id in member_ids:\n",
    "    # Filter the dataframe for the current MemberID\n",
    "    group = df[df['MemberID'] == member_id].copy()\n",
    "    \n",
    "    # Initialize a list to keep the indices of rows to be removed\n",
    "    rows_to_remove = []\n",
    "    \n",
    "    # Iterate through the group to find rows with Block_Date = 'Y'\n",
    "    for i in range(len(group)):\n",
    "        current_row = group.iloc[i]\n",
    "        \n",
    "        # Check if the current row's Block_Date is 'Y'\n",
    "        if current_row['Block_Date'] == 'Y':\n",
    "            print(f\"\\nChecking row {i} for MemberID {member_id}: {current_row.to_dict()}\")\n",
    "            \n",
    "            # Check the next row\n",
    "            if i + 1 < len(group):\n",
    "                next_row = group.iloc[i + 1]\n",
    "                \n",
    "                # If the next row ends at midnight, mark it for removal\n",
    "                if next_row['End_DateTime'].strftime('%H:%M:%S') == '00:00:00':\n",
    "                    print(f\"Marking row {i + 1} for removal (ends at midnight): {next_row.to_dict()}\")\n",
    "                    rows_to_remove.append(next_row.name)\n",
    "                \n",
    "                # Check the row two days ahead for a midnight shift\n",
    "                if i + 2 < len(group):\n",
    "                    next_day_row = group.iloc[i + 2]\n",
    "                    if next_day_row['Start_DateTime'].strftime('%H:%M:%S') == '00:00:00':\n",
    "                        print(f\"Marking row {i + 2} for removal (starts at midnight): {next_day_row.to_dict()}\")\n",
    "                        rows_to_remove.append(next_day_row.name)\n",
    "    \n",
    "    # Drop the rows identified for removal\n",
    "    cleaned_group = group.drop(index=rows_to_remove)\n",
    "    \n",
    "    if not cleaned_group.empty:\n",
    "        cleaned_dfs.append(cleaned_group)\n",
    "    else:\n",
    "        print(f\"MemberID {member_id}: Cleaned group is empty, skipping append\")\n",
    "\n",
    "print(f\"Number of cleaned dataframes: {len(cleaned_dfs)}\")\n",
    "if len(cleaned_dfs) == 0:\n",
    "    print(\"No cleaned dataframes to concatenate\")\n",
    "else:\n",
    "    df_cleaned = pd.concat(cleaned_dfs, ignore_index=True)\n",
    "    Agents_Scheduled_Block = df_cleaned\n",
    "    print(\"Final cleaned dataframe:\")\n",
    "    print(Agents_Scheduled_Block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agents_Scheduled_Block = Agents_Scheduled_Block[Agents_Scheduled_Block['Block_Date'] != 'Y'].reset_index(drop=True)\n",
    "\n",
    "Agents_Scheduled_Block = Agents_Scheduled_Block[Agents_Scheduled_Block['ProjectID'] != 0 ].reset_index(drop=True)\n",
    "Agents_Scheduled_Block['Duration'] = Agents_Scheduled_Block['Duration'].dt.total_seconds()\n",
    "Project_pd['ProjectID'] = Project_pd['ProjectID'].fillna(0).astype(str)\n",
    "Agents_Scheduled_Block['ProjectID'] = Agents_Scheduled_Block['ProjectID'].fillna(0).astype(str)\n",
    "Agents_Scheduled_Block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents_Scheduled_Block.to_excel(\"Agents_Scheduled_Block.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Schedules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
